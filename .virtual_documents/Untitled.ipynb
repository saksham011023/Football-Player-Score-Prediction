import sqlite3
import pandas as pd
import numpy as np
from sklearn.tree import DecisionTreeRegressor
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error,mean_absolute_error
from math import sqrt
from datetime import datetime


cnx=sqlite3.connect('database.sqlite')
player_data=pd.read_sql_query("SELECT * FROM Player_Attributes",cnx)
player_data.head()


player_data.shape


player_data.info()


numerical_player_data=[feature for feature in player_data.columns if player_data[feature].dtype!='O']
print(numerical_player_data)
categorical_player_data=[feature for feature in player_data.columns if player_data[feature].dtype=='O']
print(categorical_player_data)


player_data.isnull().sum()


player_data.dropna(thresh=5,inplace=True)


player_data.shape


target_data=player_data['overall_rating']
target_data


from Clean_and_Merge import Clean_and_Merge
custom_attribute_object=Clean_and_Merge()

merged_player_data=custom_attribute_object.fit_transform(player_data)
merged_player_data


from Clean_Merge_Target import Clean_and_Merge_Target

merged_target_object=Clean_and_Merge_Target()
merged_target_data=merged_target_object.fit_transform(player_data)
merged_target_data


X_train,X_test,Y_train,Y_test=train_test_split(merged_player_data,
                                               merged_target_data,
                                               test_size=0.25,
                                               random_state=101)


from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import StandardScaler
from sklearn.preprocessing import OneHotEncoder
from sklearn.impute import SimpleImputer


num_pipeline=Pipeline([
    ('num_imputer',SimpleImputer(strategy='mean')),
    ('num_scaler',StandardScaler())
])
cat_pipeline=Pipeline([
    ('cat_imputer',SimpleImputer(strategy='most_frequent')),
    ('cat_encoder',OneHotEncoder(handle_unknown='ignore'))
])

full_transformer=ColumnTransformer([
    ('num_transfromer',num_pipeline,numerical_player_data),
    ('cat_transformer',cat_pipeline,categorical_player_data)
])

target_pipeline=Pipeline([
    ('num_imputer',SimpleImputer(strategy='mean',add_indicator=True)),
    ('num_scaler',StandardScaler())
])


full_transformed_data=full_transformer.fit_transform(X_train)
full_transformed_data


full_transformed_target=target_pipeline.fit_transform(pd.DataFrame(Y_train))
full_transformed_target





def generate_file_name(filename):
    now = datetime.now()
    current = now.strftime("%d_%m_%Y-%H_%M_%S")
    
    return now.strftime("%d_%m_%Y-%H_%M_%S") + '_' + filename 





import joblib
import os


dir_name = 'pipelines'
if not os.path.isdir(dir_name):
    os.makedirs(dir_name)
    
    
joblib.dump(custom_attribute_object, os.path.join(dir_name, generate_file_name('custom_attribute_object.pkl')))
joblib.dump(merged_target_object, os.path.join(dir_name, generate_file_name('merged_target_object.pkl')))    
joblib.dump(full_transformer, os.path.join(dir_name, generate_file_name('full_transformer.pkl')))
joblib.dump(target_pipeline, os.path.join(dir_name, generate_file_name('target_pipeline.pkl')))


full_transformed_data.shape


full_transformed_target.shape





from sklearn.model_selection import cross_val_score


%%time
lin_reg=LinearRegression()

cross_val_score(estimator=lin_reg,X=full_transformed_data,
               y=full_transformed_target,cv=10,n_jobs=1)


%%time
tree_reg=DecisionTreeRegressor()
cross_val_score(estimator=tree_reg,X=full_transformed_data,
               y=full_transformed_target,cv=10,n_jobs=1)


%%time
from sklearn.svm import SVR
svm_reg=SVR()
cross_val_score(estimator=svm_reg,X=full_transformed_data,
               y=full_transformed_target,cv=10,n_jobs=1)


%%time
from xgboost import XGBRegressor
xgb_reg=XGBRegressor()
cross_val_score(estimator=xgb_reg,X=full_transformed_data,
               y=full_transformed_target,cv=10,n_jobs=1)


test_data=full_transformer.transform(X_test)
test_data


best_model_details={}





lin_reg.fit(full_transformed_data,full_transformed_target)

y_pred=lin_reg.predict(test_data)
y_pred.reshape(-1,1)
test_target=target_pipeline.transform(pd.DataFrame(Y_test))

error=sqrt(mean_squared_error(test_target,y_pred))
print("Error :",error)
best_model_Details[lin_reg]=error


tree_reg.fit(full_transformed_data,full_transformed_target)

y_pred=tree_reg.predict(test_data)
y_pred.reshape(-1,1)
test_target=target_pipeline.transform(pd.DataFrame(Y_test))

error=sqrt(mean_squared_error(test_target,y_pred))
print("Error :",error)
best_model_Details[tree_reg]=error


svm_reg.fit(X=full_transformed_data,y=full_transformed_target)

y_pred=svm_reg.predict(test_data)
y_pred.reshape(-1,1)
test_target=target_pipeline.transform(pd.DataFrame(Y_test))

error=sqrt(mean_squared_error(test_target,y_pred))
print("Error :",error)
best_model_Details[svm_reg]=error


xgb_reg.fit(X=full_transformed_data,y=full_transformed_target)

y_pred=xgb_reg.predict(test_data)
y_pred.reshape(-1,1)
test_target=target_pipeline.transform(pd.DataFrame(Y_test))

error=sqrt(mean_squared_error(test_target,y_pred))
print("Error :",error)
best_model_Details[xgb_reg]=error


best_model_Details


min_value=list(best_model_Details.values())[0]
my_model=''


for key,value in best_model_Details.items():
    if value<min_value:
        min_value=value
        my_model=key
print(f"Best performing model: {my_model} with error: {error}")


dir_name = 'models'
if not os.path.isdir(dir_name):
    os.makedirs(dir_name)
    
joblib.dump(my_model, os.path.join(dir_name, generate_file_name('best_model.pkl')))



